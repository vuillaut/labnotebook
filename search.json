[
  {
    "objectID": "posts/2022-07-27_analyse_LST-1_data.html",
    "href": "posts/2022-07-27_analyse_LST-1_data.html",
    "title": "analyse LST-1 data",
    "section": "",
    "text": "From the LST wiki page, or the elogs, find the runs you want to analyse. Find the corresponding DL1 files on the cluster, probably under /fefs/aswg/data/real/DL1/.../. These files have been automatically produced by LSTOSA, there might be several versions, corresponding to different lstchain versions. In doubt, use the last one.\n\n\n\nYou might want to sub-select the runs to use, following https://indico.cta-observatory.org/event/3984/\n\n\n\nThe AllSky MC production follows sources declinations, as explained in: - https://indico.cta-observatory.org/event/4061/contributions/33409/attachments/21211/29956/Crab_analysis_20220404.pdf - ??\nRandom forests models are trained per declination and then used on the MC test data to produce IRFs on all test pointing directions.\n\n\n\nFrom the DL1 files, you will need to produce the DL2 files using the right RF model.\n\n\nIf you are analysing an extragalactic source, the standard models trained for the closest declination of your source is likely enough. You can find these models under\n/fefs/aswg/data/models/AllSky/.../\nApply the model to the DL1 files using lstchain lstchain_dl1_to_dl2\nIn this case, you can also use the corresponding standard IRFSs, under /fefs/aswg/data/IRF/AllSky/.../.\n\n\n\nIf your source needs MC tuning (e.g. for strong NSB / galactic sources): 1. please check that a fitting custom training does not exist from https://cta-observatory.github.io/lstmcpipe/productions.html 2. if not, you may request a custom training using lstmcpipe pull-requests: https://cta-observatory.github.io/lstmcpipe/index.html#requesting-a-mc-analysis\nThe lstchain config must be produced using lstchain_tune_nsb on the DL1 files you want to analyse.\nThe lstmcpipe config must be produced following: https://cta-observatory.github.io/lstmcpipe/pipeline.html#allsky-production-pipeline\n\n\n\n\nlstchain_create_dl3_file\n\n\n\nUse gammapy to analyse the DL3 files using the corresponding IRFs."
  },
  {
    "objectID": "posts/20220701_LST1_data_flowchart.html",
    "href": "posts/20220701_LST1_data_flowchart.html",
    "title": "LST-1 data analysis worflow",
    "section": "",
    "text": "flowchart LR\n\n  R0-Protons[R0 Protons \\n - node a\\n - node b\\n - node c]\n  R0-GammaDiffuse[R0 GammaDiffuse \\n - node a\\n - node b\\n - node c]\n  R0-GammaPS[R0 Gamma PS \\n - node a\\n - node b\\n - node c]\n\n  DL1-Protons[DL1 Protons \\n - node a\\n - node b\\n - node c]\n  DL1-GammaDiffuse[DL1 GammaDiffuse \\n - node a\\n - node b\\n - node c]\n  DL1-GammaPS[DL1 Gamma PS \\n - node a\\n - node b\\n - node c]\n\n\n  R0-GammaDiffuse --> |r0_to_dl1| DL1-GammaDiffuse\n  R0-Protons --> |r0_to_dl1| DL1-Protons\n  R0-GammaPS --> |r0_to_dl1| DL1-GammaPS\n\n\n  DL1-GammaDiffuse --> |merge_dl1| DL1-GammaDiffuse-merged[DL1 Gamma Diffuse\\nall nodes]\n  DL1-Protons --> |merge_dl1| DL1-Protons-merged[DL1 Protons\\nall nodes]\n\n  DL1-GammaDiffuse-merged & DL1-Protons-merged --> train_pipe((train_pipe))\n\n  train_pipe --> models\n\n  models --> DL2-GammaPS\n\n  DL1-GammaPS --> |merge_dl1| DL1-GammaPS-merged[DL1 Gamma PS \\n - node a merged\\n - node b merged\\n - node c merged]\n  DL1-GammaPS-merged ----> DL2-GammaPS\n  DL2-GammaPS[DL2 Gamma PS \\n - node a merged\\n - node b merged\\n - node c merged]\n\n  DL2-GammaPS --> |dl2_to_irf| IRF-GammaPS\n  IRF-GammaPS[IRF Gamma PS \\n - node a merged\\n - node b merged\\n - node c merged]\n\n  RO-real --> |lstosa| DL1-real -.....-> |lstchain_dl1_to_dl2| DL2-real\n  models .-> |lstchain_dl1_to_dl2| DL2-real\n  DL2-GammaPS .-> |lstchain_create_irf_files| IRF-custom\n  DL2-real & IRF-custom .-> DL3-real\n\n\n\n\n\n\n\n\n\nPlain lines: done with lstmcpipe\nDashed lines: to be done by analyzers"
  },
  {
    "objectID": "posts/20220609_coma_aberration_bias/bias_corr_altaz.html",
    "href": "posts/20220609_coma_aberration_bias/bias_corr_altaz.html",
    "title": "Correcting coma aberration bias",
    "section": "",
    "text": "Code\nfrom lstchain.io.io import dl2_params_lstcam_key\nfrom ctapipe.io import read_table\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport ctaplot\nimport astropy.units as u\nfrom astropy.visualization import quantity_support\nfrom copy import deepcopy\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nctaplot.set_style('notebook')"
  },
  {
    "objectID": "posts/20220609_coma_aberration_bias/bias_corr_altaz.html#correcting-the-bias",
    "href": "posts/20220609_coma_aberration_bias/bias_corr_altaz.html#correcting-the-bias",
    "title": "Correcting coma aberration bias",
    "section": "Correcting the bias",
    "text": "Correcting the bias\nWe can reconstruct the source position in the sky with a different focal length. To visualize the bias, we can plot it as a function of alpha, the angle between the event position and the X-axis\n\n\nCode\nfrom lstchain.reco.utils import reco_source_position_sky\n\n\n\n\nCode\ndef patch_events(events, true_focal_length=29.04*u.m, plot=True):\n    \n    raltaz = reco_source_position_sky(events['x'], events['y'],\n                                  events['reco_disp_dx'], events['reco_disp_dy'],\n                                  true_focal_length,\n                                  events['alt_tel'], \n                                  events['az_tel'])\n    \n    events_corr = deepcopy(events)\n    events_corr['reco_alt'] = raltaz.alt.to(u.rad)\n    events_corr['reco_az'] = raltaz.az.to(u.rad)\n    \n    if plot:\n        plt.figure(figsize=(10,6))\n        opt = dict(bins=20)\n        ctaplot.plots.plot_binned_bias(events['mc_alt'], \n                                   events['reco_alt'],\n                                   events['alpha'],\n                                   **opt,\n                                   label='alt no corr'\n                                  )\n\n        ctaplot.plots.plot_binned_bias(events['mc_az'], \n                                       events['reco_az'],\n                                       events['alpha'],\n                                       **opt,\n                                       label='az no corr'\n                                      )\n\n        x = np.linspace(-np.pi, np.pi, 100)\n        plt.plot(x, np.cos(x)*0.0008, label='alt model')\n        plt.plot(x, np.sin(x)*0.0028\n                 , label='az model')\n\n        ctaplot.plots.plot_binned_bias(events_corr['mc_alt'], \n                                   events_corr['reco_alt'],\n                                   events_corr['alpha'],\n                                   **opt,\n                                   label='alt bias corrected',\n                                  )\n\n        ctaplot.plots.plot_binned_bias(events_corr['mc_az'], \n                                       events_corr['reco_az'],\n                                       events_corr['alpha'],\n                                       **opt,\n                                       label='az bias corrected',\n                                      )\n        plt.xlabel('alpha [rad]')\n\n        plt.legend()\n        plt.show()\n        plot_all(events_corr)\n    \n    return events_corr\n    \n\n\n\n\nCode\nparams_patched = patch_events(bright_events);\n\n\n\n\n\n\n\n\nWe can see that a bias is still present.\nLet’s find the effective focal length that minimize the bias.\n\n\nCode\nfocal_lengths = np.linspace(28.2, 29.2, num=10) * u.m\nbias_alt = []\nbias_az = [] \nfor fl in focal_lengths:\n    print(fl)\n    pe = patch_events(bright_events, true_focal_length=fl);\n    _, bias = ctaplot.ana.bias_per_bin(pe['mc_alt'], pe['reco_alt'], pe['alpha'])\n    bias_alt.append(np.rad2deg(np.mean(np.abs(bias))))\n    _, bias = ctaplot.ana.bias_per_bin(pe['mc_az'], pe['reco_az'], pe['alpha'])\n    bias_az.append(np.rad2deg(np.mean(np.abs(bias))))\n\n\n28.2 m\n\n\n\n\n\n\n\n\n28.31111111111111 m\n\n\n\n\n\n\n\n\n28.42222222222222 m\n\n\n\n\n\n\n\n\n28.53333333333333 m\n\n\n\n\n\n\n\n\n28.644444444444442 m\n\n\n\n\n\n\n\n\n28.755555555555556 m\n\n\n\n\n\n\n\n\n28.866666666666667 m\n\n\n\n\n\n\n\n\n28.977777777777778 m\n\n\n\n\n\n\n\n\n29.08888888888889 m\n\n\n\n\n\n\n\n\n29.2 m\n\n\n\n\n\n\n\n\nWe can find the effective focal length that minimize the bias:\n\n\nCode\nplt.plot(focal_lengths, bias_alt, label='alt')\nplt.plot(focal_lengths, bias_az, label='az')\nplt.title('Minimizing the bias')\nplt.xlabel('effective focal length [m]')\nplt.ylabel('bias [degrees]')\nplt.legend()\n\nassert np.argmin(bias_alt) == np.argmin(bias_az)\nprint(f\"The focal length that minimize the bias: {focal_lengths[np.argmin(bias_alt)]:.3f}\")\n\n\nThe focal length that minimize the bias: 28.756 m\n\n\n\n\n\nLet’s see the results with that focal length:\n\n\nCode\nparams_patched = patch_events(bright_events, focal_lengths[np.argmin(bias_alt)], plot=False);\nadd_params(params_patched)\n\n\n\n\nCode\nedges = np.histogram_bin_edges(params_patched['alpha'].value, bins=5)\nfor ii, low in enumerate(edges[:-1]):\n    selected_events = params_patched[(low<bright_events['alpha'])&(params_patched['alpha']<edges[ii+1])]\n    plot_all(selected_events)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe alpha-dependence is now gone"
  },
  {
    "objectID": "posts/20220609_coma_aberration_bias/bias_corr_altaz.html#angular-resolution-before-and-after",
    "href": "posts/20220609_coma_aberration_bias/bias_corr_altaz.html#angular-resolution-before-and-after",
    "title": "Correcting coma aberration bias",
    "section": "Angular resolution before and after",
    "text": "Angular resolution before and after\n\n\nCode\nselected_events = params[(params['intensity']>100) & (params['gammaness']>0.4)]\nselected_corr = patch_events(selected_events, plot=False)\n\n\n\n\nCode\nctaplot.plot_angular_resolution_per_energy(selected_events['mc_alt'].quantity,\n                                           selected_events['reco_alt'].quantity,\n                                           selected_events['mc_az'].quantity,\n                                           selected_events['reco_az'].quantity,\n                                           selected_events['reco_energy'].quantity,)\n\nctaplot.plot_angular_resolution_per_energy(selected_corr['mc_alt'].quantity,\n                                           selected_corr['reco_alt'].quantity,\n                                           selected_corr['mc_az'].quantity,\n                                           selected_corr['reco_az'].quantity,\n                                           selected_corr['reco_energy'].quantity,)\n\n\nctaplot.plot_angular_resolution_cta_requirement('north', color='black')\nplt.ylim(0, 0.4)\n\n\n(0.0, 0.4)"
  },
  {
    "objectID": "posts/20220609_coma_aberration_bias/bias_corr_altaz.html#testing-the-same-correction-on-point-source-gammas",
    "href": "posts/20220609_coma_aberration_bias/bias_corr_altaz.html#testing-the-same-correction-on-point-source-gammas",
    "title": "Correcting coma aberration bias",
    "section": "Testing the same correction on point source gammas",
    "text": "Testing the same correction on point source gammas\n\n\nCode\nfilename = 'dl2_gamma_20deg_180deg_off0.4deg_20220215_v0.9.1_prod5_trans_80_local_tailcut_8_4_testing.h5'\n\ndef analyis(filename):\n    params = read_table(filename, path=dl2_params_lstcam_key)\n    add_params(params)\n    # bright_events = params[(params['intensity']>5000)]\n    bright_events = params[(params['intensity']>50) & ((params['gammaness']>0.7))]\n    bright_events_corr = patch_events(bright_events, true_focal_length=29.04*u.m, plot=False)\n\n\n    fig, axes = plt.subplots(1, 3, figsize=(20,5))\n    \n    plot_psf(bright_events_corr, ax=axes[0])\n\n    opt=dict(bins=50,  histtype='step', range=(0, 0.1))\n    ctaplot.plot_theta2(bright_events['mc_alt'].quantity,\n                       bright_events['reco_alt'].quantity,\n                       bright_events['mc_az'].quantity,\n                       bright_events['reco_az'].quantity,\n                        ax=axes[1],\n                        label='no bias correction',\n                        **opt\n                       )\n    \n    ctaplot.plot_theta2(bright_events_corr['mc_alt'].quantity,\n                   bright_events_corr['reco_alt'].quantity,\n                   bright_events_corr['mc_az'].quantity,\n                   bright_events_corr['reco_az'].quantity,\n                        ax=axes[1],\n                    label='bias corrected',\n                        **opt\n                   )\n    axes[1].legend()\n    \n    ctaplot.plot_angular_resolution_per_energy(bright_events['mc_alt'].quantity,\n                                           bright_events['reco_alt'].quantity,\n                                           bright_events['mc_az'].quantity,\n                                           bright_events['reco_az'].quantity,\n                                           bright_events['reco_energy'].quantity,\n                                                  ax=axes[-1],\n                                             label='no bias correction',  \n                                              )\n\n\n    ctaplot.plot_angular_resolution_per_energy(bright_events_corr['mc_alt'].quantity,\n                                               bright_events_corr['reco_alt'].quantity,\n                                               bright_events_corr['mc_az'].quantity,\n                                               bright_events_corr['reco_az'].quantity,\n                                               bright_events_corr['reco_energy'].quantity,\n                                               ax=axes[-1],\n                                               label='bias corrected',\n                                               # ls='--'\n                                              )\n\n    ctaplot.plot_angular_resolution_cta_requirement('north', color='black', ax=axes[-1])\n    axes[-1].set_ylim(0, 0.4)\n\n\n\n\nCode\nanalyis(filename)"
  },
  {
    "objectID": "posts/conda_config.html",
    "href": "posts/conda_config.html",
    "title": "conda config",
    "section": "",
    "text": "May evolve in time.\n\n\nSee https://conda.github.io/conda-libmamba-solver/getting-started/\nInstall Anaconda or Miniconda: https://docs.conda.io/en/latest/miniconda.html#linux-installers\nconda install -n base conda-libmamba-solver\nconda config --set solver libmamba\nDon’t install anything else in base.\n\n\n\nhttps://github.com/vuillaut/myenvs\nconda config --add channels vuillaut\nconda create -n jlab jlab\n\n\n\nTo add a conda env to the jupyter/ipython kernels:\nfunction addkernel(){\n  conda activate $1\n  ipython kernel install --name \"$1\" --user\n}\n\naddkernel myenv\nThis way you can run the jupyterlab interface without prefered plugins but run different computing kernels."
  },
  {
    "objectID": "posts/2022-03-01_singularity_jupyterlab_must.html",
    "href": "posts/2022-03-01_singularity_jupyterlab_must.html",
    "title": "Running JupyterLab in a singularity container on MUST",
    "section": "",
    "text": "singularity recipe\nBootstrap: docker\nFrom: continuumio/anaconda3:latest\n\n%environment\n    export PATH=\"/opt/conda/bin:$PATH\"\n\n%post\n    # Installation de pip\n    conda install -y -c anaconda pip\n\n    # Installation de la librairie CTAplot avec pip\n    pip install ctaplot\n\n    # Création du répertoire .jupyter\n    mkdir /root/.jupyter\n\n    # Création du fichier de configuration de Jupyter Lab\n    touch /root/.jupyter/jupyter_notebook_config.py\n\n    # Configuration de Jupyter Lab\n    echo \"c.NotebookApp.ip = '0.0.0.0'\" >> /root/.jupyter/jupyter_notebook_config.py\n    echo \"c.NotebookApp.open_browser = False\" >> /root/.jupyter/jupyter_notebook_config.py\n    echo \"c.NotebookApp.port = 8888\" >> /root/.jupyter/jupyter_notebook_config.py\n\n    # Exposition du port de Jupyter Lab\n    export PORT=8888\n    echo \"export PORT=8888\" >> /root/.bashrc\n\n    # Modification des permissions du répertoire .jupyter\n    chmod -R 777 /root/.jupyter\n\n%runscript\n    jupyter lab --allow-root --port $PORT --no-browser\n\n\n2. Building the image\nsingularity build jup.sif jup.def\n\n\n3. Executing the container\nsingularity exec --bind $PWD:/run/user jup.sif jupyter-lab --no-browser --ip=127.0.0.1 --NotebookApp.token=''\n\n\n4. S’y connecter depuis son laptop\nDans un autre terminal\nssh -L 8888:127.0.0.1:8888 username@lappusmb.in2p3.fr"
  },
  {
    "objectID": "posts/2022-07-22_conda_must_config.html",
    "href": "posts/2022-07-22_conda_must_config.html",
    "title": "conda must config",
    "section": "",
    "text": "Use shared conda\n__conda_setup=\"$('/usr/bin/conda' 'shell.bash' 'hook' 2> /dev/null)\"\neval \"$__conda_setup\"\n\n\nSetup config\nconda config\nWill generate a .condarc file in the home directory.\nEdit this file to add the following:\nenvs_dirs:\n  - /mustfs/CONTAINERS/conda/glearn/envs/\n\npkgs_dirs:\n  - /mustfs/CONTAINERS/conda/glearn/pkgs/\n\nchannels:\n  - conda-forge\n  - defaults\nChanging pkgs_dirs and envs_dirs is necessary to avoid hitting disk quotas in your own home directory. Create new directories to set these paths. This will avoid mutli-users installation and writing rights issues."
  },
  {
    "objectID": "posts/2022-09-01_ctapipe_hdf5_r0.html",
    "href": "posts/2022-09-01_ctapipe_hdf5_r0.html",
    "title": "ctapipe generate R1/DL0 HDF5",
    "section": "",
    "text": "ctapipe generate HDF5 with R1/DL0 waveforms\nctapipe-quickstart\nwill generate a base config\nEdit the config with:\n  write_showers: true # store DL2 stereo geometry\n  write_raw_waveforms: true # write R0 waveforms\n  write_waveforms: true # write R1 waveforms\n  transform_waveform: true\n  waveform_dtype: \"uint16\"\n  waveform_offset: 400\n  waveform_scale: 80\nThe waveforms are scaled to fit in uint16 and scaled back at reading.\nThen run:\nctapipe-process --config base_config.yaml --input ../Simtel/prod5/gamma_20deg_0deg_run5___cta-prod5-paranal_desert-2147m-Paranal-dark.simtel.zst --output gamma_20deg_0deg_run5___cta-prod5-paranal_desert-2147m-Paranal-dark.h5"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Personnal blog-like laboratory notebook."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Personnal blog-like laboratory notebook.",
    "section": "",
    "text": "Running JupyterLab in a singularity container on MUST\n\n\n\n\n\n\n\nnotes\n\n\n\n\n\n\n\n\n\n\n\nMar 1, 2023\n\n\nThomas Vuillaume\n\n\n\n\n\n\n\n\nconda config\n\n\n\n\n\n\n\nnotes\n\n\n\n\n\n\n\n\n\n\n\nJan 11, 2023\n\n\nThomas Vuillaume\n\n\n\n\n\n\n\n\nctapipe generate R1/DL0 HDF5\n\n\n\n\n\n\n\nnotes\n\n\n\n\n\n\n\n\n\n\n\nSep 1, 2022\n\n\nThomas Vuillaume\n\n\n\n\n\n\n\n\nanalyse LST-1 data\n\n\n\n\n\n\n\nnotes\n\n\n\n\n\n\n\n\n\n\n\nJul 27, 2022\n\n\nThomas Vuillaume\n\n\n\n\n\n\n\n\nconda must config\n\n\n\n\n\n\n\nnotes\n\n\n\n\n\n\n\n\n\n\n\nJul 22, 2022\n\n\nThomas Vuillaume\n\n\n\n\n\n\n\n\nLST-1 data analysis worflow\n\n\n\n\n\n\n\nnotes\n\n\ncta\n\n\n\n\n\n\n\n\n\n\n\nJul 1, 2022\n\n\nThomas Vuillaume\n\n\n\n\n\n\n\n\nCorrecting coma aberration bias\n\n\n\n\n\n\n\nnotes\n\n\ncta\n\n\n\n\nLST-1 study of the coma aberration bias correction\n\n\n\n\n\n\nJun 9, 2022\n\n\nThomas Vuillaume\n\n\n\n\n\n\nNo matching items"
  }
]