[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Personnal blog-like laboratory notebook."
  },
  {
    "objectID": "posts/2023-06-01_docker_cpu.html",
    "href": "posts/2023-06-01_docker_cpu.html",
    "title": "Docker desktop on MAC OSX using 100% CPU",
    "section": "",
    "text": "Solved the problem doing:\nOpen the config in Docker desktop.\n\nAdd debug: false in Docker Engine config\nTurn off Use gRPC FUSE for file sharing\nTurn off Send usage statistics\n\nNote: from ~July 2023, docker desktop on mac osx has an experimental feature Resource Saver mode: when this is set, Docker will use minimal CPU and memory when idle To enable: Settings / Features in development / Access experimental features"
  },
  {
    "objectID": "posts/2022-07-27_analyse_LST-1_data.html",
    "href": "posts/2022-07-27_analyse_LST-1_data.html",
    "title": "analyse LST-1 data",
    "section": "",
    "text": "From the LST wiki page, or the elogs, find the runs you want to analyse. Find the corresponding DL1 files on the cluster, probably under /fefs/aswg/data/real/DL1/.../. These files have been automatically produced by LSTOSA, there might be several versions, corresponding to different lstchain versions. In doubt, use the last one.\n\n\n\nYou might want to sub-select the runs to use, following https://indico.cta-observatory.org/event/3984/\n\n\n\nThe AllSky MC production follows sources declinations, as explained in: - https://indico.cta-observatory.org/event/4061/contributions/33409/attachments/21211/29956/Crab_analysis_20220404.pdf - ??\nRandom forests models are trained per declination and then used on the MC test data to produce IRFs on all test pointing directions.\n\n\n\nFrom the DL1 files, you will need to produce the DL2 files using the right RF model.\n\n\nIf you are analysing an extragalactic source, the standard models trained for the closest declination of your source is likely enough. You can find these models under\n/fefs/aswg/data/models/AllSky/.../\nApply the model to the DL1 files using lstchain lstchain_dl1_to_dl2\nIn this case, you can also use the corresponding standard IRFSs, under /fefs/aswg/data/IRF/AllSky/.../.\n\n\n\nIf your source needs MC tuning (e.g. for strong NSB / galactic sources): 1. please check that a fitting custom training does not exist from https://cta-observatory.github.io/lstmcpipe/productions.html 2. if not, you may request a custom training using lstmcpipe pull-requests: https://cta-observatory.github.io/lstmcpipe/index.html#requesting-a-mc-analysis\nThe lstchain config must be produced using lstchain_tune_nsb on the DL1 files you want to analyse.\nThe lstmcpipe config must be produced following: https://cta-observatory.github.io/lstmcpipe/pipeline.html#allsky-production-pipeline\n\n\n\n\nlstchain_create_dl3_file\n\n\n\nUse gammapy to analyse the DL3 files using the corresponding IRFs."
  },
  {
    "objectID": "posts/2022-07-27_analyse_LST-1_data.html#get-the-data",
    "href": "posts/2022-07-27_analyse_LST-1_data.html#get-the-data",
    "title": "analyse LST-1 data",
    "section": "",
    "text": "From the LST wiki page, or the elogs, find the runs you want to analyse. Find the corresponding DL1 files on the cluster, probably under /fefs/aswg/data/real/DL1/.../. These files have been automatically produced by LSTOSA, there might be several versions, corresponding to different lstchain versions. In doubt, use the last one."
  },
  {
    "objectID": "posts/2022-07-27_analyse_LST-1_data.html#select-the-data",
    "href": "posts/2022-07-27_analyse_LST-1_data.html#select-the-data",
    "title": "analyse LST-1 data",
    "section": "",
    "text": "You might want to sub-select the runs to use, following https://indico.cta-observatory.org/event/3984/"
  },
  {
    "objectID": "posts/2022-07-27_analyse_LST-1_data.html#corresponding-mc-production",
    "href": "posts/2022-07-27_analyse_LST-1_data.html#corresponding-mc-production",
    "title": "analyse LST-1 data",
    "section": "",
    "text": "The AllSky MC production follows sources declinations, as explained in: - https://indico.cta-observatory.org/event/4061/contributions/33409/attachments/21211/29956/Crab_analysis_20220404.pdf - ??\nRandom forests models are trained per declination and then used on the MC test data to produce IRFs on all test pointing directions."
  },
  {
    "objectID": "posts/2022-07-27_analyse_LST-1_data.html#produce-your-dl2-files",
    "href": "posts/2022-07-27_analyse_LST-1_data.html#produce-your-dl2-files",
    "title": "analyse LST-1 data",
    "section": "",
    "text": "From the DL1 files, you will need to produce the DL2 files using the right RF model.\n\n\nIf you are analysing an extragalactic source, the standard models trained for the closest declination of your source is likely enough. You can find these models under\n/fefs/aswg/data/models/AllSky/.../\nApply the model to the DL1 files using lstchain lstchain_dl1_to_dl2\nIn this case, you can also use the corresponding standard IRFSs, under /fefs/aswg/data/IRF/AllSky/.../.\n\n\n\nIf your source needs MC tuning (e.g. for strong NSB / galactic sources): 1. please check that a fitting custom training does not exist from https://cta-observatory.github.io/lstmcpipe/productions.html 2. if not, you may request a custom training using lstmcpipe pull-requests: https://cta-observatory.github.io/lstmcpipe/index.html#requesting-a-mc-analysis\nThe lstchain config must be produced using lstchain_tune_nsb on the DL1 files you want to analyse.\nThe lstmcpipe config must be produced following: https://cta-observatory.github.io/lstmcpipe/pipeline.html#allsky-production-pipeline"
  },
  {
    "objectID": "posts/2022-07-27_analyse_LST-1_data.html#produce-your-dl3-files",
    "href": "posts/2022-07-27_analyse_LST-1_data.html#produce-your-dl3-files",
    "title": "analyse LST-1 data",
    "section": "",
    "text": "lstchain_create_dl3_file"
  },
  {
    "objectID": "posts/2022-07-27_analyse_LST-1_data.html#high-level-analysis",
    "href": "posts/2022-07-27_analyse_LST-1_data.html#high-level-analysis",
    "title": "analyse LST-1 data",
    "section": "",
    "text": "Use gammapy to analyse the DL3 files using the corresponding IRFs."
  },
  {
    "objectID": "posts/2023-04-18_singularity_conda.html",
    "href": "posts/2023-04-18_singularity_conda.html",
    "title": "Singularity and Conda",
    "section": "",
    "text": "Based on the excellent post https://geniac.readthedocs.io/en/version-2.4.1/conda.html\nBootstrap: docker\nFrom: gitlab-registry.in2p3.fr/gammalearn/gammalearn/mamba:master\n\n%post\n    conda create -n glearn astropy \\\n    && conda clean -a \\\n    && echo -e \"#! /bin/bash\\n\\n# script to activate the conda environment\" &gt; ~/.bashrc \\\n    && conda init bash \\\n    && echo -e \"\\nconda activate glearn\" &gt;&gt; ~/.bashrc \\\n    && mkdir -p /opt/etc/ && cp ~/.bashrc /opt/etc/bashrc\n\n\n%environment\n    # Activate Conda environment\n    export PATH=\"$HOME/miniconda/envs/glearn/bin:$PATH\"\n    source /opt/etc/bashrc\nBootstrap: docker\nFrom: gitlab-registry.in2p3.fr/gammalearn/gammalearn:v0.10\n\n%post\n    echo -e \"#! /bin/bash\\n\\n# script to activate the conda environment\" &gt; ~/.bashrc \\\n    && conda init bash \\\n    && echo -e \"\\nconda activate glearn\" &gt;&gt; ~/.bashrc \\\n    && mkdir -p /opt/etc/ && cp ~/.bashrc /opt/etc/bashrc\n\n\n%environment\n    # Activate Conda environment\n    export PATH=\"/opt/conda/envs/glearn/bin:$PATH\"\n    source /opt/etc/bashrc"
  },
  {
    "objectID": "posts/2023-08-29_linux_rights.html",
    "href": "posts/2023-08-29_linux_rights.html",
    "title": "Setting linux directories writing rights to users",
    "section": "",
    "text": "problem\nIn workdir, a directory I created\nI want to:\n\nspecific user named user1 to be able to create dirs and write his own files in /workdir/\nI keep writing and reading rights in /workdir/ and all future subdirs and files\nuser1 is not able to modify my files and dirs in /workdir/\n\nI can’t create a new group or deal with groups\n\n\nhow to solve\nAdd umask 002 in my .bashrc\ncd /workdir\nsetfacl -d -m u:your_username:rwx .\n\nsetfacl -m u:user1:rwx .\nsetfacl -d -m u:user1:rwx .\n\nchmod +t ."
  },
  {
    "objectID": "posts/2022-03-01_singularity_jupyterlab_must.html",
    "href": "posts/2022-03-01_singularity_jupyterlab_must.html",
    "title": "Running JupyterLab in a singularity container on MUST",
    "section": "",
    "text": "singularity recipe\nBootstrap: docker\nFrom: continuumio/anaconda3:latest\n\n%environment\n    export PATH=\"/opt/conda/bin:$PATH\"\n\n%post\n    # Installation de pip\n    conda install -y -c anaconda pip\n\n    # Installation de la librairie CTAplot avec pip\n    pip install ctaplot\n\n    # Création du répertoire .jupyter\n    mkdir /root/.jupyter\n\n    # Création du fichier de configuration de Jupyter Lab\n    touch /root/.jupyter/jupyter_notebook_config.py\n\n    # Configuration de Jupyter Lab\n    echo \"c.NotebookApp.ip = '0.0.0.0'\" &gt;&gt; /root/.jupyter/jupyter_notebook_config.py\n    echo \"c.NotebookApp.open_browser = False\" &gt;&gt; /root/.jupyter/jupyter_notebook_config.py\n    echo \"c.NotebookApp.port = 8888\" &gt;&gt; /root/.jupyter/jupyter_notebook_config.py\n\n    # Exposition du port de Jupyter Lab\n    export PORT=8888\n    echo \"export PORT=8888\" &gt;&gt; /root/.bashrc\n\n    # Modification des permissions du répertoire .jupyter\n    chmod -R 777 /root/.jupyter\n\n%runscript\n    jupyter lab --allow-root --port $PORT --no-browser\n\n\n2. Building the image\nsingularity build jup.sif jup.def\n\n\n3. Executing the container\nsingularity exec --bind $PWD:/run/user jup.sif jupyter-lab --no-browser --ip=127.0.0.1 --NotebookApp.token=''\n\n\n4. S’y connecter depuis son laptop\nDans un autre terminal\nssh -L 8888:127.0.0.1:8888 username@lappusmb.in2p3.fr"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Personnal blog-like laboratory notebook.",
    "section": "",
    "text": "Setting linux directories writing rights to users\n\n\n\n\n\n\n\nnotes\n\n\n\n\n\n\n\n\n\n\n\nAug 29, 2023\n\n\nThomas Vuillaume\n\n\n\n\n\n\n  \n\n\n\n\nDocker desktop on MAC OSX using 100% CPU\n\n\n\n\n\n\n\nnotes\n\n\n\n\n\n\n\n\n\n\n\nJun 1, 2023\n\n\nThomas Vuillaume\n\n\n\n\n\n\n  \n\n\n\n\nSingularity and Conda\n\n\n\n\n\n\n\nnotes\n\n\n\n\n\n\n\n\n\n\n\nApr 18, 2023\n\n\nThomas Vuillaume\n\n\n\n\n\n\n  \n\n\n\n\nRunning JupyterLab in a singularity container on MUST\n\n\n\n\n\n\n\nnotes\n\n\n\n\n\n\n\n\n\n\n\nMar 1, 2023\n\n\nThomas Vuillaume\n\n\n\n\n\n\n  \n\n\n\n\nconda config\n\n\n\n\n\n\n\nnotes\n\n\n\n\n\n\n\n\n\n\n\nJan 11, 2023\n\n\nThomas Vuillaume\n\n\n\n\n\n\n  \n\n\n\n\nctapipe generate R1/DL0 HDF5\n\n\n\n\n\n\n\nnotes\n\n\n\n\n\n\n\n\n\n\n\nSep 1, 2022\n\n\nThomas Vuillaume\n\n\n\n\n\n\n  \n\n\n\n\nanalyse LST-1 data\n\n\n\n\n\n\n\nnotes\n\n\n\n\n\n\n\n\n\n\n\nJul 27, 2022\n\n\nThomas Vuillaume\n\n\n\n\n\n\n  \n\n\n\n\nconda must config\n\n\n\n\n\n\n\nnotes\n\n\n\n\n\n\n\n\n\n\n\nJul 22, 2022\n\n\nThomas Vuillaume\n\n\n\n\n\n\n  \n\n\n\n\nLST-1 data analysis worflow\n\n\n\n\n\n\n\nnotes\n\n\ncta\n\n\n\n\n\n\n\n\n\n\n\nJul 1, 2022\n\n\nThomas Vuillaume\n\n\n\n\n\n\n  \n\n\n\n\nCorrecting coma aberration bias\n\n\n\n\n\n\n\nnotes\n\n\ncta\n\n\n\n\nLST-1 study of the coma aberration bias correction\n\n\n\n\n\n\nJun 9, 2022\n\n\nThomas Vuillaume\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2022-09-01_ctapipe_hdf5_r0.html",
    "href": "posts/2022-09-01_ctapipe_hdf5_r0.html",
    "title": "ctapipe generate R1/DL0 HDF5",
    "section": "",
    "text": "ctapipe generate HDF5 with R1/DL0 waveforms\nctapipe-quickstart\nwill generate a base config\nEdit the config with:\n  write_showers: true # store DL2 stereo geometry\n  write_raw_waveforms: true # write R0 waveforms\n  write_waveforms: true # write R1 waveforms\n  transform_waveform: true\n  waveform_dtype: \"uint16\"\n  waveform_offset: 400\n  waveform_scale: 80\nThe waveforms are scaled to fit in uint16 and scaled back at reading.\nThen run:\nctapipe-process --config base_config.yaml --input ../Simtel/prod5/gamma_20deg_0deg_run5___cta-prod5-paranal_desert-2147m-Paranal-dark.simtel.zst --output gamma_20deg_0deg_run5___cta-prod5-paranal_desert-2147m-Paranal-dark.h5"
  },
  {
    "objectID": "posts/20220701_LST1_data_flowchart.html",
    "href": "posts/20220701_LST1_data_flowchart.html",
    "title": "LST-1 data analysis worflow",
    "section": "",
    "text": "flowchart LR\n\n  R0-Protons[R0 Protons \\n - node a\\n - node b\\n - node c]\n  R0-GammaDiffuse[R0 GammaDiffuse \\n - node a\\n - node b\\n - node c]\n  R0-GammaPS[R0 Gamma PS \\n - node a\\n - node b\\n - node c]\n\n  DL1-Protons[DL1 Protons \\n - node a\\n - node b\\n - node c]\n  DL1-GammaDiffuse[DL1 GammaDiffuse \\n - node a\\n - node b\\n - node c]\n  DL1-GammaPS[DL1 Gamma PS \\n - node a\\n - node b\\n - node c]\n\n\n  R0-GammaDiffuse --&gt; |r0_to_dl1| DL1-GammaDiffuse\n  R0-Protons --&gt; |r0_to_dl1| DL1-Protons\n  R0-GammaPS --&gt; |r0_to_dl1| DL1-GammaPS\n\n\n  DL1-GammaDiffuse --&gt; |merge_dl1| DL1-GammaDiffuse-merged[DL1 Gamma Diffuse\\nall nodes]\n  DL1-Protons --&gt; |merge_dl1| DL1-Protons-merged[DL1 Protons\\nall nodes]\n\n  DL1-GammaDiffuse-merged & DL1-Protons-merged --&gt; train_pipe((train_pipe))\n\n  train_pipe --&gt; models\n\n  models --&gt; DL2-GammaPS\n\n  DL1-GammaPS --&gt; |merge_dl1| DL1-GammaPS-merged[DL1 Gamma PS \\n - node a merged\\n - node b merged\\n - node c merged]\n  DL1-GammaPS-merged ----&gt; DL2-GammaPS\n  DL2-GammaPS[DL2 Gamma PS \\n - node a merged\\n - node b merged\\n - node c merged]\n\n  DL2-GammaPS --&gt; |dl2_to_irf| IRF-GammaPS\n  IRF-GammaPS[IRF Gamma PS \\n - node a merged\\n - node b merged\\n - node c merged]\n\n  RO-real --&gt; |lstosa| DL1-real -.....-&gt; |lstchain_dl1_to_dl2| DL2-real\n  models .-&gt; |lstchain_dl1_to_dl2| DL2-real\n  DL2-GammaPS .-&gt; |lstchain_create_irf_files| IRF-custom\n  DL2-real & IRF-custom .-&gt; DL3-real\n\n\n\n\n\n\nPlain lines: done with lstmcpipe\nDashed lines: to be done by analyzers"
  },
  {
    "objectID": "posts/20220609_coma_aberration_bias/bias_corr_altaz.html",
    "href": "posts/20220609_coma_aberration_bias/bias_corr_altaz.html",
    "title": "Correcting coma aberration bias",
    "section": "",
    "text": "Code\nfrom lstchain.io.io import dl2_params_lstcam_key\nfrom ctapipe.io import read_table\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport ctaplot\nimport astropy.units as u\nfrom astropy.visualization import quantity_support\nfrom copy import deepcopy\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nctaplot.set_style('notebook')\nCode\n# Reading DL2 parameters\n\nfilename = 'dl2_gamma-diffuse_20deg_180deg_20220215_v0.9.1_prod5_trans_80_local_tailcut_8_4_testing.h5'\nparams = read_table(filename, path=dl2_params_lstcam_key)\nCode\nparams[:4]\n\n\n\nTable length=4\n\nobs_idevent_idintensitylog_intensityxyrphilengthlength_uncertaintywidthwidth_uncertaintypsiskewnesskurtosistime_gradientinterceptleakage_intensity_width_1leakage_intensity_width_2leakage_pixels_width_1leakage_pixels_width_2n_pixelsconcentration_cogconcentration_coreconcentration_pixeln_islandsalt_telaz_telcalibration_idmc_energylog_mc_energymc_altmc_azmc_core_xmc_core_ymc_h_first_intmc_typemc_az_telmc_alt_telmc_x_maxmc_core_distancewltel_idtel_pos_xtel_pos_ytel_pos_ztrigger_typetrigger_timeevent_typedisp_dxdisp_dydisp_normdisp_angledisp_signsrc_xsrc_ylog_reco_energyreco_energyreco_disp_normreco_disp_signreco_disp_dxreco_disp_dyreco_src_xreco_src_ysigned_time_gradientsigned_skewnessreco_altreco_azreco_typegammaness\nint32int64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float32float32float64float64int64float64float64float64int64float32float32int64float64float64float64float64float64float64float64int64float32float32float64float64float64int64float32float32float32int64float64int64float32float32float32float32float32float32float32float64float64float64float32float64float64float64float64float64float64float64float64int64float64\n1001709204.691669464111332.311100168117379-0.9429552882748465-0.0269576669362539020.9433405490554008-3.11301194919339340.234438603433601370.0078422699881002010.049864477210902860.002820204535803679-0.4176405820038234-0.076179366145008951.91617966015168583.158349431562738712.5877506351235180.100735320.23272440.0010781671159029650.0026954177897574125170.232599608790322180.38632659203980240.1231618798467566111.22173053.1415927-10.10125340521335602-0.99459036228117161.17378842830657963.155841827392578117.61976623535156-120.9898757934570326547.11523437503.14159271.2217305290.8888854980469200.75099945937570.212697382088891661-70.93-52.0743.0321606861253.33423132-0.39838670.181398140.43774107-0.427279-1.0-1.3413420.15444046-1.14141249823460030.072208363388064910.46018360223014054-1.0-0.42063011995620920.18665275231598732-1.36358540823105570.159695085379733433.1583494315627387-0.076179366145008951.17299157911605233.15629815008605251010.4760000000000001\n100114702217.46422433853152.3373878201397390.460728340928599430.363365243998680140.58677500345621410.66779763331754360.116625116825143440.0048114807151058070.0537388680402243950.002788135479311323-1.0265033637403687-0.0383849316998664262.48053926335876662.748325297976986512.3493308386246630.00.00.00.0120.53900221839869670.39936006652944170.221835966629967411.22173053.1415927-10.0735081136226654-1.13366472204401661.22850549221038823.214990139007568442.88823699951172-197.0823059082031218002.34960937503.14159271.2217305219.3333282470703184.345219890478660.460782972854769551-70.93-52.0743.0321606861265.15868932-0.247248650.325900260.40907562-0.92177355-1.00.21347970.6892655-1.22318082100537070.0598162494811730960.30984948357431924-1.0-0.16044420044510360.26507425566207620.300284140483495830.62843949966075632.7483252979769865-0.0383849316998664261.23174262488649783.209116810285751010.3741666666666666\n100115008165.506139755249022.218814109364702-0.9169175343015934-0.40885725896150971.0039432368989956-2.7221501232647110.077661954272045640.0033586928472081870.069267845379087150.0031922758184949524-1.477054216302340.58120401348858492.2382191567652474-3.026177055962925512.3968614725557430.127804590.59622810.00161725067385444750.0037735849056603774100.52844817890861140.273803418517280350.2546447834400062411.22173053.1415927-10.06741833686828613-1.1712219652210831.18636918067932133.1234266757965090.5827245712280273-149.9759216308593821047.28320312503.14159271.2217305188.18182373046875121.242069305143560.89191478669781621-70.93-52.0743.0321606861266.30892832-0.071568220.217989340.22943705-1.253573-1.0-0.98848575-0.19086792-1.1691163702078060.067745995633085850.21682144939570283-1.0-0.020295544965148090.21586947855734717-0.9372130792667415-0.19298778040416253-3.02617705596292550.58120401348858491.18819881175506333.1231402459886931010.0455\n1001240065026.3798446655273.7012553052292714-0.46367241536546555-0.082357610007603550.4709298086732346-2.9658057346182480.322248640715590730.00355458230495727050.078745762415324360.0012247855781627778-0.04766358667702001-0.89759372661622663.446251471675243-3.336247707080466415.7476675263774340.00.00.00.0640.186266628290241380.449535054129446170.0933368727446329721.22173053.1415927-11.00427675247192380.0018534095311007061.22196137905120853.1297266483306885-205.5702667236328-40.5134811401367224701.789062503.14159271.2217305335.6097412109375135.13531907809270.244363365631148051-70.93-52.0743.0321606861279.03483320.4707722-0.0312043430.47180524-0.0661864951.00.0070998-0.11356195-0.0187872323993603370.95766313040243230.46634585480762541.00.46581622875101053-0.0222193008090054430.0021438133855449792-0.1045769108166093.33624770708046640.89759372661622661.2217878633150463.13067074037698400.96\nCode\ndef add_params(events):\n    \"\"\"\n    add some parameters and units\n    \"\"\"\n    for pos in ['reco_src_x', 'reco_src_y', 'src_x', 'src_y', 'reco_disp_dx', 'reco_disp_dy', 'x', 'y']:\n        events[pos].unit = u.m\n    \n    for ang in ['reco_alt', 'reco_az', 'mc_alt', 'mc_az', 'alt_tel', 'az_tel']:\n        events[ang].unit = u.rad\n        \n    for ene in ['reco_energy', 'mc_energy']:\n        events[ene].unit = u.TeV\n    \n    events['diff_x'] = events['reco_src_x'] - events['src_x']\n    events['diff_y'] = events['reco_src_y'] - events['src_y']\n    events['diff_alt'] = events['reco_alt'] - events['mc_alt']\n    events['diff_az'] = events['reco_az'] - events['mc_az']\n    events['diff'] = np.sqrt(events['diff_x']**2 + events['diff_y']**2)\n    events['offset'] = ctaplot.ana.ana.angular_separation_altaz(events['alt_tel'].quantity, events['az_tel'].quantity,\n                                                                events['mc_alt'].quantity, events['mc_az'].quantity)\n    events['alpha'] = np.arctan2(events['src_y'], events['src_x'])\nCode\nadd_params(params)\nCode\ndef plot_true_pos(events, ax=None):\n    ax = plt.gca() if ax is None else ax\n    ax.scatter(events['src_x'], events['src_y'], s=1);\n    ax.grid(True)\n    ax.axis('equal')\n    ax.set_xlabel('src_x')\n    ax.set_ylabel('src_y')\n    ax.set_title('events position')\n    return ax\n\nplot_true_pos(params);\nCode\ndef plot_psf(events, ax=None):\n    ax = plt.gca() if ax is None else ax\n    rx = 1.6\n    ry = 0.4\n    # ax.hist2d(events['diff_x'], events['diff_y'], bins=100, range=[[-r,r],[-r,r]]);\n    diff_az = events['reco_az'] - events['mc_az']\n    diff_alt = events['reco_alt'] - events['mc_alt']\n    with quantity_support():\n        ax.hist2d(diff_az.to(u.deg), diff_alt.to(u.deg), \n              bins=120, range=[[-rx,rx],[-ry,ry]], cmap='hot')\n    ax.grid(True)\n    # ax.axis('equal')\n    ax.set_xlabel('diff_az [rad]')\n    ax.set_ylabel('diff_alt [rad]')\n    ax.set_title('PSF')\n    return ax\n\nplot_psf(params);\nCode\ndef plot_theta2(events, ax=None, bias_correction=True):\n    ax = plt.gca() if ax is None else ax\n    opt = dict(bins=100, range=(0, 0.05), density=True, histtype='step', bias_correction=False, lw=2)\n    ax=ctaplot.plots.plot_theta2(events['mc_alt'].quantity,  \n                                 events['reco_alt'].quantity, \n                                 events['mc_az'].quantity, \n                                 events['reco_az'].quantity,\n                                 ax=ax, \n                                 label='no bias correction',\n                                 **opt)\n    \n    if bias_correction:\n        opt['bias_correction'] = True\n        ax=ctaplot.plots.plot_theta2(events['mc_alt'].quantity,\n                                     events['reco_alt'].quantity,\n                                     events['mc_az'].quantity,\n                                     events['reco_az'].quantity,\n                                     ax=ax, label='bias corrected', **opt)\n        ax.legend()\n    return ax\n\nplot_theta2(params, bias_correction=True);\nCode\ndef plot_bias_per_offset(events, ax=None, **kwargs):\n    offset, bias_alt = ctaplot.ana.bias_per_bin(events['mc_alt'], events['reco_alt'], events['offset'], bins=20)\n    offset, bias_az = ctaplot.ana.bias_per_bin(events['mc_az'], events['reco_az'], events['offset'], bins=20)\n    ax = plt.gca() if ax is None else ax\n    ax.stairs(np.rad2deg(bias_alt), edges=np.rad2deg(offset), label='bias in alt', **kwargs)\n    ax.stairs(np.rad2deg(bias_az), edges=np.rad2deg(offset), label='bias in az', **kwargs)\n    ax.set_xlabel('offset in degrees')\n    ax.set_ylabel('bias in degrees')\n    ax.legend()\n    return ax\n\ndef plot_bias_per_alpha(events, ax=None, **kwargs):\n    alpha, bias_alt = ctaplot.ana.bias_per_bin(events['mc_alt'], events['reco_alt'], events['alpha'], bins=20)\n    alpha, bias_az = ctaplot.ana.bias_per_bin(events['mc_az'], events['reco_az'], events['alpha'], bins=20)\n    ax = plt.gca() if ax is None else ax\n    ax.stairs(np.rad2deg(bias_alt), edges=np.rad2deg(alpha), label='bias in alt', **kwargs)\n    ax.stairs(np.rad2deg(bias_az), edges=np.rad2deg(alpha), label='bias in az', **kwargs)\n    ax.set_xlabel('alpha in degrees')\n    ax.set_ylabel('bias in degrees')\n    ax.legend()\n    return ax\n\nplot_bias_per_offset(params);\nplt.show()\nplot_bias_per_alpha(params);\nCode\n# Select bright events to see the effect\n\nbright_events = params[(params['intensity']&gt;500)]\n# selected_events = bright_events[(bright_events['src_x']&gt;0) & (bright_events['src_y']&gt;0)]\nselected_events = bright_events[(-np.pi/4&lt;bright_events['alpha'])&(bright_events['alpha']&lt;np.pi/4.)]\nCode\ndef plot_all(events):\n    fig, axes = plt.subplots(1, 5, figsize=(25,5))\n    plot_true_pos(events, ax=axes[0])\n    plot_psf(events, ax=axes[1])\n    plot_theta2(events, ax=axes[2])\n    plot_bias_per_offset(events, ax=axes[3])\n    plot_bias_per_alpha(events, ax=axes[4])\n    plt.tight_layout()\n    plt.show()\nCode\nprint(\"Bright events\")\nplot_all(bright_events)\n\n\nBright events"
  },
  {
    "objectID": "posts/20220609_coma_aberration_bias/bias_corr_altaz.html#correcting-the-bias",
    "href": "posts/20220609_coma_aberration_bias/bias_corr_altaz.html#correcting-the-bias",
    "title": "Correcting coma aberration bias",
    "section": "Correcting the bias",
    "text": "Correcting the bias\nWe can reconstruct the source position in the sky with a different focal length. To visualize the bias, we can plot it as a function of alpha, the angle between the event position and the X-axis\n\n\nCode\nfrom lstchain.reco.utils import reco_source_position_sky\n\n\n\n\nCode\ndef patch_events(events, true_focal_length=29.04*u.m, plot=True):\n    \n    raltaz = reco_source_position_sky(events['x'], events['y'],\n                                  events['reco_disp_dx'], events['reco_disp_dy'],\n                                  true_focal_length,\n                                  events['alt_tel'], \n                                  events['az_tel'])\n    \n    events_corr = deepcopy(events)\n    events_corr['reco_alt'] = raltaz.alt.to(u.rad)\n    events_corr['reco_az'] = raltaz.az.to(u.rad)\n    \n    if plot:\n        plt.figure(figsize=(10,6))\n        opt = dict(bins=20)\n        ctaplot.plots.plot_binned_bias(events['mc_alt'], \n                                   events['reco_alt'],\n                                   events['alpha'],\n                                   **opt,\n                                   label='alt no corr'\n                                  )\n\n        ctaplot.plots.plot_binned_bias(events['mc_az'], \n                                       events['reco_az'],\n                                       events['alpha'],\n                                       **opt,\n                                       label='az no corr'\n                                      )\n\n        x = np.linspace(-np.pi, np.pi, 100)\n        plt.plot(x, np.cos(x)*0.0008, label='alt model')\n        plt.plot(x, np.sin(x)*0.0028\n                 , label='az model')\n\n        ctaplot.plots.plot_binned_bias(events_corr['mc_alt'], \n                                   events_corr['reco_alt'],\n                                   events_corr['alpha'],\n                                   **opt,\n                                   label='alt bias corrected',\n                                  )\n\n        ctaplot.plots.plot_binned_bias(events_corr['mc_az'], \n                                       events_corr['reco_az'],\n                                       events_corr['alpha'],\n                                       **opt,\n                                       label='az bias corrected',\n                                      )\n        plt.xlabel('alpha [rad]')\n\n        plt.legend()\n        plt.show()\n        plot_all(events_corr)\n    \n    return events_corr\n    \n\n\n\n\nCode\nparams_patched = patch_events(bright_events);\n\n\n\n\n\n\n\n\nWe can see that a bias is still present.\nLet’s find the effective focal length that minimize the bias.\n\n\nCode\nfocal_lengths = np.linspace(28.2, 29.2, num=10) * u.m\nbias_alt = []\nbias_az = [] \nfor fl in focal_lengths:\n    print(fl)\n    pe = patch_events(bright_events, true_focal_length=fl);\n    _, bias = ctaplot.ana.bias_per_bin(pe['mc_alt'], pe['reco_alt'], pe['alpha'])\n    bias_alt.append(np.rad2deg(np.mean(np.abs(bias))))\n    _, bias = ctaplot.ana.bias_per_bin(pe['mc_az'], pe['reco_az'], pe['alpha'])\n    bias_az.append(np.rad2deg(np.mean(np.abs(bias))))\n\n\n28.2 m\n28.31111111111111 m\n28.42222222222222 m\n28.53333333333333 m\n28.644444444444442 m\n28.755555555555556 m\n28.866666666666667 m\n28.977777777777778 m\n29.08888888888889 m\n29.2 m\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can find the effective focal length that minimize the bias:\n\n\nCode\nplt.plot(focal_lengths, bias_alt, label='alt')\nplt.plot(focal_lengths, bias_az, label='az')\nplt.title('Minimizing the bias')\nplt.xlabel('effective focal length [m]')\nplt.ylabel('bias [degrees]')\nplt.legend()\n\nassert np.argmin(bias_alt) == np.argmin(bias_az)\nprint(f\"The focal length that minimize the bias: {focal_lengths[np.argmin(bias_alt)]:.3f}\")\n\n\nThe focal length that minimize the bias: 28.756 m\n\n\n\n\n\nLet’s see the results with that focal length:\n\n\nCode\nparams_patched = patch_events(bright_events, focal_lengths[np.argmin(bias_alt)], plot=False);\nadd_params(params_patched)\n\n\n\n\nCode\nedges = np.histogram_bin_edges(params_patched['alpha'].value, bins=5)\nfor ii, low in enumerate(edges[:-1]):\n    selected_events = params_patched[(low&lt;bright_events['alpha'])&(params_patched['alpha']&lt;edges[ii+1])]\n    plot_all(selected_events)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe alpha-dependence is now gone"
  },
  {
    "objectID": "posts/20220609_coma_aberration_bias/bias_corr_altaz.html#angular-resolution-before-and-after",
    "href": "posts/20220609_coma_aberration_bias/bias_corr_altaz.html#angular-resolution-before-and-after",
    "title": "Correcting coma aberration bias",
    "section": "Angular resolution before and after",
    "text": "Angular resolution before and after\n\n\nCode\nselected_events = params[(params['intensity']&gt;100) & (params['gammaness']&gt;0.4)]\nselected_corr = patch_events(selected_events, plot=False)\n\n\n\n\nCode\nctaplot.plot_angular_resolution_per_energy(selected_events['mc_alt'].quantity,\n                                           selected_events['reco_alt'].quantity,\n                                           selected_events['mc_az'].quantity,\n                                           selected_events['reco_az'].quantity,\n                                           selected_events['reco_energy'].quantity,)\n\nctaplot.plot_angular_resolution_per_energy(selected_corr['mc_alt'].quantity,\n                                           selected_corr['reco_alt'].quantity,\n                                           selected_corr['mc_az'].quantity,\n                                           selected_corr['reco_az'].quantity,\n                                           selected_corr['reco_energy'].quantity,)\n\n\nctaplot.plot_angular_resolution_cta_requirement('north', color='black')\nplt.ylim(0, 0.4)\n\n\n(0.0, 0.4)"
  },
  {
    "objectID": "posts/20220609_coma_aberration_bias/bias_corr_altaz.html#testing-the-same-correction-on-point-source-gammas",
    "href": "posts/20220609_coma_aberration_bias/bias_corr_altaz.html#testing-the-same-correction-on-point-source-gammas",
    "title": "Correcting coma aberration bias",
    "section": "Testing the same correction on point source gammas",
    "text": "Testing the same correction on point source gammas\n\n\nCode\nfilename = 'dl2_gamma_20deg_180deg_off0.4deg_20220215_v0.9.1_prod5_trans_80_local_tailcut_8_4_testing.h5'\n\ndef analyis(filename):\n    params = read_table(filename, path=dl2_params_lstcam_key)\n    add_params(params)\n    # bright_events = params[(params['intensity']&gt;5000)]\n    bright_events = params[(params['intensity']&gt;50) & ((params['gammaness']&gt;0.7))]\n    bright_events_corr = patch_events(bright_events, true_focal_length=29.04*u.m, plot=False)\n\n\n    fig, axes = plt.subplots(1, 3, figsize=(20,5))\n    \n    plot_psf(bright_events_corr, ax=axes[0])\n\n    opt=dict(bins=50,  histtype='step', range=(0, 0.1))\n    ctaplot.plot_theta2(bright_events['mc_alt'].quantity,\n                       bright_events['reco_alt'].quantity,\n                       bright_events['mc_az'].quantity,\n                       bright_events['reco_az'].quantity,\n                        ax=axes[1],\n                        label='no bias correction',\n                        **opt\n                       )\n    \n    ctaplot.plot_theta2(bright_events_corr['mc_alt'].quantity,\n                   bright_events_corr['reco_alt'].quantity,\n                   bright_events_corr['mc_az'].quantity,\n                   bright_events_corr['reco_az'].quantity,\n                        ax=axes[1],\n                    label='bias corrected',\n                        **opt\n                   )\n    axes[1].legend()\n    \n    ctaplot.plot_angular_resolution_per_energy(bright_events['mc_alt'].quantity,\n                                           bright_events['reco_alt'].quantity,\n                                           bright_events['mc_az'].quantity,\n                                           bright_events['reco_az'].quantity,\n                                           bright_events['reco_energy'].quantity,\n                                                  ax=axes[-1],\n                                             label='no bias correction',  \n                                              )\n\n\n    ctaplot.plot_angular_resolution_per_energy(bright_events_corr['mc_alt'].quantity,\n                                               bright_events_corr['reco_alt'].quantity,\n                                               bright_events_corr['mc_az'].quantity,\n                                               bright_events_corr['reco_az'].quantity,\n                                               bright_events_corr['reco_energy'].quantity,\n                                               ax=axes[-1],\n                                               label='bias corrected',\n                                               # ls='--'\n                                              )\n\n    ctaplot.plot_angular_resolution_cta_requirement('north', color='black', ax=axes[-1])\n    axes[-1].set_ylim(0, 0.4)\n\n\n\n\nCode\nanalyis(filename)"
  },
  {
    "objectID": "posts/conda_config.html",
    "href": "posts/conda_config.html",
    "title": "conda config",
    "section": "",
    "text": "May evolve in time.\n\n\nSee https://conda.github.io/conda-libmamba-solver/getting-started/\nInstall Anaconda or Miniconda: https://docs.conda.io/en/latest/miniconda.html#linux-installers\nconda install -n base conda-libmamba-solver\nconda config --set solver libmamba\nDon’t install anything else in base.\n\n\n\nhttps://github.com/vuillaut/myenvs\nconda config --add channels vuillaut\nconda create -n jlab jlab\n\n\n\nTo add a conda env to the jupyter/ipython kernels:\nfunction addkernel(){\n  conda activate $1\n  ipython kernel install --name \"$1\" --user\n}\n\naddkernel myenv\nThis way you can run the jupyterlab interface without prefered plugins but run different computing kernels."
  },
  {
    "objectID": "posts/conda_config.html#libmamba-solver-for-conda",
    "href": "posts/conda_config.html#libmamba-solver-for-conda",
    "title": "conda config",
    "section": "",
    "text": "See https://conda.github.io/conda-libmamba-solver/getting-started/\nInstall Anaconda or Miniconda: https://docs.conda.io/en/latest/miniconda.html#linux-installers\nconda install -n base conda-libmamba-solver\nconda config --set solver libmamba\nDon’t install anything else in base."
  },
  {
    "objectID": "posts/conda_config.html#my-envs",
    "href": "posts/conda_config.html#my-envs",
    "title": "conda config",
    "section": "",
    "text": "https://github.com/vuillaut/myenvs\nconda config --add channels vuillaut\nconda create -n jlab jlab"
  },
  {
    "objectID": "posts/conda_config.html#jupyter-lab",
    "href": "posts/conda_config.html#jupyter-lab",
    "title": "conda config",
    "section": "",
    "text": "To add a conda env to the jupyter/ipython kernels:\nfunction addkernel(){\n  conda activate $1\n  ipython kernel install --name \"$1\" --user\n}\n\naddkernel myenv\nThis way you can run the jupyterlab interface without prefered plugins but run different computing kernels."
  },
  {
    "objectID": "posts/2022-07-22_conda_must_config.html",
    "href": "posts/2022-07-22_conda_must_config.html",
    "title": "conda must config",
    "section": "",
    "text": "Use shared conda\n__conda_setup=\"$('/usr/bin/conda' 'shell.bash' 'hook' 2&gt; /dev/null)\"\neval \"$__conda_setup\"\n\n\nSetup config\nconda config\nWill generate a .condarc file in the home directory.\nEdit this file to add the following:\nenvs_dirs:\n  - /mustfs/CONTAINERS/conda/glearn/envs/\n\npkgs_dirs:\n  - /mustfs/CONTAINERS/conda/glearn/pkgs/\n\nchannels:\n  - conda-forge\n  - defaults\nChanging pkgs_dirs and envs_dirs is necessary to avoid hitting disk quotas in your own home directory. Create new directories to set these paths. This will avoid mutli-users installation and writing rights issues."
  }
]